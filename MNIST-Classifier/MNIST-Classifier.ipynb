{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from scipy.misc import imread\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset if not present already\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Image dimensions of the MNIST dataset\n",
    "ROWS, COLS = 28, 28\n",
    "NUM_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Convolutional layers that act as feature detectors\n",
    "feature_layers = [\n",
    "    \n",
    "    Conv2D(32, 5, padding='valid', input_shape=(ROWS, COLS, 1)),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Conv2D(16, 5),\n",
    "    Activation('relu'),\n",
    "\n",
    "    MaxPooling2D(2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "# Define the fully connected layers\n",
    "classification_layers = [\n",
    "    \n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASS),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the Model and compile the Model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use tensorboard to monitor the progress \n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_data(x_data, y_data):\n",
    "    \"\"\" Reshape the input images to (# of images, rows, cols, channels)\n",
    "        Convert Y to categorical type using one-hot encoding\n",
    "        return the new X and Y\n",
    "    \"\"\"\n",
    "    X = x_data.reshape((x_data.shape[0], ROWS, COLS, 1)).astype('float32')\n",
    "    X /= 255\n",
    "    Y = to_categorical(y_data, NUM_CLASS)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training and the validation dataset\n",
    "X_train, Y_train = pre_process_data(x_train, y_train)\n",
    "X_valid, Y_valid = pre_process_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2889 - acc: 0.9115 - val_loss: 0.0535 - val_acc: 0.9845\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 157s 3ms/step - loss: 0.0953 - acc: 0.9722 - val_loss: 0.0412 - val_acc: 0.9875\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0711 - acc: 0.9784 - val_loss: 0.0328 - val_acc: 0.9891\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0580 - acc: 0.9823 - val_loss: 0.0262 - val_acc: 0.9909\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0485 - acc: 0.9853 - val_loss: 0.0267 - val_acc: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, Y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "             callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the structure of the model into a json file\n",
    "model_json = model.to_json()\n",
    "with open(\"mnist_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Store the learned weights of the parameter\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation set : 99.09% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model on the validation set : {}% \".format(history.history['val_acc'][-1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
